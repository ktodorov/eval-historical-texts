{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "\n",
    "sys.argv = [\n",
    "\"--device cuda\",\n",
    "\"--data-folder\", \"..\\\\data\",\n",
    "\"--seed\", \"13\",\n",
    "\"--configuration\", \"char-to-char-encoder-decoder\",\n",
    "\"--language\", language,\n",
    "\"--challenge\", \"post-ocr-correction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure container:\n",
    "from dependency_injection.ioc_container import IocContainer\n",
    "\n",
    "container = IocContainer()\n",
    "\n",
    "data_service = container.data_service()\n",
    "plot_service = container.plot_service()\n",
    "# vocabulary_service = container.vocabulary_service()\n",
    "metrics_service = container.metrics_service()\n",
    "# cache_service = container.cache_service()\n",
    "process_service = container.process_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_data = cache_service.get_item_from_cache(\n",
    "#     item_key='char-vocabulary')\n",
    "\n",
    "# vocabulary_service.initialize_vocabulary_data(vocabulary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'eval-historical-texts'\n",
    "project = 'post-ocr-correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_runs = {\n",
    "    'none': 'h512-e128-l2-bi-d0.50.0001',\n",
    "    'fast-text': 'ft-h512-e128-l2-bi-d0.50.0001',\n",
    "    'bert': 'pretr-h512-e128-l2-bi-d0.50.0001',\n",
    "    'both': 'pretr-ft-h512-e128-l2-bi-d0.50.0001',\n",
    "    'bert-finetune': 'pretr-h512-e128-l2-bi-d0.5-tune0.0001',\n",
    "    'both-finetune': 'pretr-ft-h512-e128-l2-bi-d0.5-tune0.0001',\n",
    "    'bert-finetune-ac': 'pretr-h512-e128-l2-bi-d0.5-tune-ac0.0001',\n",
    "    'both-finetune-ac': 'pretr-ft-h512-e128-l2-bi-d0.5-tune-ac0.0001',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_info(language: str, checkpoint_name: str):\n",
    "    output_path = os.path.join('..', 'results', 'post-ocr-correction', 'char-to-char-encoder-decoder', language, 'output')\n",
    "    csv_path = os.path.join(output_path, f'output-BEST_{language}--{checkpoint_name}.csv')\n",
    "    pickle_name = f'output-BEST_{language}--{checkpoint_name}'\n",
    "    \n",
    "    run_info = data_service.load_python_obj(output_path, pickle_name, print_on_success=False, print_on_error=False)\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        return None\n",
    "    \n",
    "    with open(csv_path, 'r', encoding='utf-8') as csv_file:\n",
    "        lines = csv_file.read().splitlines()\n",
    "        last_line = lines[-1]\n",
    "        improvement_percentage = round(float(last_line.split(',')[0].split('Improvement percentage: ')[-1]), 2)\n",
    "        run_info['improvement_percentage'] = improvement_percentage\n",
    "        \n",
    "    input_characters =[]\n",
    "    predicted_characters = []\n",
    "    target_characters = []\n",
    "    with open(csv_path, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            input_data = row['Input']\n",
    "            predicted_data = row['Prediction']\n",
    "            target_data = row['Target']\n",
    "            \n",
    "            if target_data == '' or target_data is None:\n",
    "                break\n",
    "                \n",
    "            \n",
    "            input_characters.append(input_data)\n",
    "            predicted_characters.append(predicted_data)\n",
    "            target_characters.append(target_data)\n",
    "            \n",
    "#         predicted_tokens = [process_service._vocabulary_service.ids_to_string(\n",
    "#             x, exclude_special_tokens=True) for x in predicted_characters]\n",
    "#         target_tokens = [process_service._vocabulary_service.ids_to_string(\n",
    "#             x, exclude_special_tokens=True) for x in target_characters]\n",
    "        jaccard_scores = [metrics_service.calculate_jaccard_similarity(\n",
    "            target_characters[i], input_characters[i]) for i in range(len(input_characters))]\n",
    "    \n",
    "        pr_jaccard_scores = [metrics_service.calculate_jaccard_similarity(\n",
    "            target_characters[i], predicted_characters[i]) for i in range(len(predicted_characters))]     \n",
    "        \n",
    "        original_levenshtein_distances = [metrics_service.calculate_levenshtein_distance(\n",
    "            target_characters[i], input_characters[i]) for i in range(len(input_characters))]\n",
    "    \n",
    "        levenshtein_distances = [metrics_service.calculate_levenshtein_distance(\n",
    "            target_characters[i], predicted_characters[i]) for i in range(len(predicted_characters))]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         batch_jaccard_scores = []\n",
    "#         for i in range(0, len(jaccard_scores), 32):\n",
    "#             batch_jaccard_scores.append(np.mean(jaccard_scores[i:i+32]))\n",
    "        \n",
    "        run_info['improvement_percentage'] = round((1 - (float(sum(levenshtein_distances)) / sum(original_levenshtein_distances))) * 100, 3)\n",
    "        run_info['jaccard-similarities'] = pr_jaccard_scores\n",
    "        run_info[\"edit-distances\"] = levenshtein_distances\n",
    "        run_info[\"original-edit-distances\"] = original_levenshtein_distances\n",
    "        \n",
    "        run_info['original-jaccard-scores'] = jaccard_scores\n",
    "        run_info['original-jaccard-score'] = round(np.mean(jaccard_scores), 3)\n",
    "    \n",
    "    return run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(xs, ys, color='r'):\n",
    "    new_xs = []\n",
    "    new_ys = []\n",
    "\n",
    "    for x, y in zip(xs, ys):\n",
    "        if y > -1:\n",
    "            new_xs.append(x)\n",
    "            new_ys.append(y)\n",
    "\n",
    "    # plt.plot(new_xs, new_ys, color)\n",
    "    plt.fill_between(new_xs, new_ys, interpolate=True, color=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none            , seed 13 |   -5.968; sum:   9.958; jacc mean:  0.821; jacc percent:     -0.450 || 9.958 & -5.968 & 0.821 & -0.45                                                                      \n",
      "fast-text       , seed 13 |   -5.735; sum:   9.936; jacc mean:  0.824; jacc percent:     -0.035 || 9.936 & -5.735 & 0.824 & -0.035                                                                     \n",
      "bert            , seed 13 |   -8.840; sum:  10.228; jacc mean:  0.822; jacc percent:     -0.364 || 10.228 & -8.84 & 0.822 & -0.364                                                                     \n",
      "bert            , seed  7 |  -61.873; sum:  15.211; jacc mean:  0.732; jacc percent:    -11.253 || 15.211 & -61.873 & 0.732 & -11.253                                                                  \n",
      "both            , seed 13 |   -7.658; sum:  10.116; jacc mean:  0.821; jacc percent:     -0.482 || 10.116 & -7.658 & 0.821 & -0.482                                                                    \n",
      "both            , seed  7 |   -6.338; sum:   9.992; jacc mean:  0.825; jacc percent:     -0.006 || 9.992 & -6.338 & 0.825 & -0.006                                                                     \n",
      "bert-finetune   , seed 13 |   -7.915; sum:  10.141; jacc mean:  0.820; jacc percent:     -0.562 || 10.141 & -7.915 & 0.82 & -0.562                                                                     \n",
      "bert-finetune   , seed  7 |   -4.665; sum:   9.835; jacc mean:  0.825; jacc percent:      0.062 || 9.835 & -4.665 & 0.825 & 0.062                                                                      \n",
      "both-finetune   , seed 13 |   -5.977; sum:   9.958; jacc mean:  0.822; jacc percent:     -0.303 || 9.958 & -5.977 & 0.822 & -0.303                                                                     \n",
      "bert-finetune-ac, seed 13 |   -3.483; sum:   9.724; jacc mean:  0.829; jacc percent:      0.510 || 9.724 & -3.483 & 0.829 & 0.51                                                                       \n",
      "both-finetune-ac, seed 13 |   -8.382; sum:  10.184; jacc mean:  0.821; jacc percent:     -0.418 || 10.184 & -8.382 & 0.821 & -0.418                                                                    \n",
      "both-finetune-ac, seed  7 |   -7.215; sum:  10.075; jacc mean:  0.820; jacc percent:     -0.574 || 10.075 & -7.215 & 0.82 & -0.574                                                                     \n",
      "-----------\n",
      "original jaccard similarity mean: 0.825\n",
      "original edit mean: 9.397\n"
     ]
    }
   ],
   "source": [
    "original_edit_distances = {}\n",
    "edit_distances_per_run = {}\n",
    "\n",
    "for run_name, run_unique_str in unique_runs.items():\n",
    "    for seed in [13, 7, 42]:\n",
    "        checkpoint_name = f'{run_unique_str}-seed{seed}'\n",
    "        run_info = get_run_info(language, checkpoint_name)\n",
    "        if run_info is None:\n",
    "            continue\n",
    "    \n",
    "        original_jaccard = run_info['original-jaccard-score']\n",
    "        original_jaccards = sum(run_info['original-jaccard-scores'])\n",
    "        jaccards = sum(run_info['jaccard-similarities'])\n",
    "        jaccard_improvement_percentage = -round(((1 - (float(jaccards) / original_jaccards)) * 100), 3)\n",
    "        \n",
    "        original_edit_mean = round(np.mean(run_info[\"original-edit-distances\"]), 3)\n",
    "        \n",
    "        original_edit_sum = sum(run_info[\"original-edit-distances\"])\n",
    "        predicted_edit_sum = sum(run_info[\"edit-distances\"])\n",
    "        improvement_percentage = run_info['improvement_percentage']\n",
    "        jaccard_similarity_mean = round(np.mean(run_info['jaccard-similarities']), 3)\n",
    "        edit_dist = round(np.mean(run_info[\"edit-distances\"]), 3)\n",
    "        print('{:16s}, seed {:2d} | {:8.3f}; sum: {:7.3f}; jacc mean: {:6.3f}; jacc percent: {:10.3f} || {:100s}'.format(run_name, seed, improvement_percentage, edit_dist, jaccard_similarity_mean, jaccard_improvement_percentage,\n",
    "                                                                                                                      f'{edit_dist} & {improvement_percentage} & {jaccard_similarity_mean} & {jaccard_improvement_percentage}'))\n",
    "        \n",
    "        original_edit_distances = run_info[\"original-edit-distances\"]\n",
    "        edit_distances_per_run[run_name] = [run_info[\"edit-distances\"][i] for i in range(len(original_edit_distances))]\n",
    "    \n",
    "print('-----------')\n",
    "print(f\"original jaccard similarity mean: {original_jaccard}\")\n",
    "print(f\"original edit mean: {original_edit_mean}\")\n",
    "\n",
    "\n",
    "edit_distances_per_run['original'] = [x for x in original_edit_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_values = [1, 0.6, 0.3, 0.2]\n",
    "\n",
    "# norm_values = {}\n",
    "\n",
    "# # bins = np.arange(0, 10000, 2)\n",
    "\n",
    "# for i, (run_name, edit_distances) in enumerate(edit_distances_per_run.items()):\n",
    "    \n",
    "#     rounded_distances = [x for x in edit_distances]\n",
    "#     counter_values = Counter(rounded_distances)\n",
    "# #     counter_values = Counter()\n",
    "# #     current_index = 0\n",
    "# #     for key, value in temp_values.items():\n",
    "# #         if key >= bins[current_index]:\n",
    "# #             current_index += 1\n",
    "            \n",
    "# #         counter_values[current_index] += value\n",
    "        \n",
    "#     x = [v for v in list(sorted(counter_values.keys())) if v < 20]\n",
    "#     y = [counter_values[key] for key in x]\n",
    "#     norm_y = [(float(i)/sum(y)) * 100 for i in y]\n",
    "#     norm_values[run_name] = norm_y\n",
    "    \n",
    "    \n",
    "#     plt.fill_between(x, norm_y, interpolate=True, alpha=alpha_values[i])\n",
    "    \n",
    "\n",
    "# plt.legend(edit_distances_per_run.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)",
   "language": "python",
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
