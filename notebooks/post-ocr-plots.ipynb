{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "\n",
    "sys.argv = [\n",
    "\"--device cuda\",\n",
    "\"--data-folder\", \"..\\\\data\",\n",
    "\"--seed\", \"13\",\n",
    "\"--configuration\", \"char-to-char-encoder-decoder\",\n",
    "\"--language\", language,\n",
    "\"--challenge\", \"post-ocr-correction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure container:\n",
    "from dependency_injection.ioc_container import IocContainer\n",
    "\n",
    "container = IocContainer()\n",
    "\n",
    "data_service = container.data_service()\n",
    "plot_service = container.plot_service()\n",
    "metrics_service = container.metrics_service()\n",
    "process_service = container.process_service()\n",
    "file_service = container.file_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'eval-historical-texts'\n",
    "project = 'post-ocr-correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_runs = {\n",
    "    'Base': 'h512-e128-l2-bi-d0.50.0001',\n",
    "#     'Base + FT': 'ft-h512-e128-l2-bi-d0.50.0001',\n",
    "#     'Base + BERT': 'pretr-h512-e128-l2-bi-d0.50.0001',\n",
    "#     'Base + FT + BERT': 'pretr-ft-h512-e128-l2-bi-d0.50.0001',\n",
    "#     'Base + BERT (fine-tuned)': 'pretr-h512-e128-l2-bi-d0.5-tune0.0001',\n",
    "#     'Base + FT + BERT (fine-tuned)': 'pretr-ft-h512-e128-l2-bi-d0.5-tune0.0001',\n",
    "#     'Base + BERT (fine-tuned, after convergence)': 'pretr-h512-e128-l2-bi-d0.5-tune-ac0.0001',\n",
    "    'Base + FT + BERT (fine-tuned, after convergence)': 'pretr-ft-h512-e128-l2-bi-d0.5-tune-ac0.0001',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_info(language: str, checkpoint_name: str):\n",
    "    output_path = os.path.join('..', 'results', 'post-ocr-correction', 'char-to-char-encoder-decoder', language, 'output')\n",
    "    csv_path = os.path.join(output_path, f'output-BEST_{language}--{checkpoint_name}.csv')\n",
    "    pickle_name = f'output-BEST_{language}--{checkpoint_name}'\n",
    "    \n",
    "    run_info = data_service.load_python_obj(output_path, pickle_name, print_on_success=False, print_on_error=False)\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        return None\n",
    "    \n",
    "    with open(csv_path, 'r', encoding='utf-8') as csv_file:\n",
    "        lines = csv_file.read().splitlines()\n",
    "        last_line = lines[-1]\n",
    "        improvement_percentage = round(float(last_line.split(',')[0].split('Improvement percentage: ')[-1]), 2)\n",
    "        run_info['improvement_percentage'] = improvement_percentage\n",
    "        \n",
    "    input_characters =[]\n",
    "    predicted_characters = []\n",
    "    target_characters = []\n",
    "    with open(csv_path, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            input_data = row['Input']\n",
    "            predicted_data = row['Prediction']\n",
    "            target_data = row['Target']\n",
    "            \n",
    "            if target_data == '' or target_data is None:\n",
    "                break\n",
    "                \n",
    "            \n",
    "            input_characters.append(input_data)\n",
    "            predicted_characters.append(predicted_data)\n",
    "            target_characters.append(target_data)\n",
    "            \n",
    "#         predicted_tokens = [process_service._vocabulary_service.ids_to_string(\n",
    "#             x, exclude_special_tokens=True) for x in predicted_characters]\n",
    "#         target_tokens = [process_service._vocabulary_service.ids_to_string(\n",
    "#             x, exclude_special_tokens=True) for x in target_characters]\n",
    "        jaccard_scores = [metrics_service.calculate_jaccard_similarity(\n",
    "            target_characters[i], input_characters[i]) for i in range(len(input_characters))]\n",
    "    \n",
    "        pr_jaccard_scores = [metrics_service.calculate_jaccard_similarity(\n",
    "            target_characters[i], predicted_characters[i]) for i in range(len(predicted_characters))]     \n",
    "        \n",
    "        original_levenshtein_distances = [metrics_service.calculate_levenshtein_distance(\n",
    "            target_characters[i], input_characters[i]) for i in range(len(input_characters))]\n",
    "    \n",
    "        levenshtein_distances = [metrics_service.calculate_levenshtein_distance(\n",
    "            target_characters[i], predicted_characters[i]) for i in range(len(predicted_characters))]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         batch_jaccard_scores = []\n",
    "#         for i in range(0, len(jaccard_scores), 32):\n",
    "#             batch_jaccard_scores.append(np.mean(jaccard_scores[i:i+32]))\n",
    "        \n",
    "        run_info['improvement_percentage'] = round((1 - (float(sum(levenshtein_distances)) / sum(original_levenshtein_distances))) * 100, 3)\n",
    "        run_info['jaccard-similarities'] = pr_jaccard_scores\n",
    "        run_info[\"edit-distances\"] = levenshtein_distances\n",
    "        run_info[\"original-edit-distances\"] = original_levenshtein_distances\n",
    "        \n",
    "        run_info['original-jaccard-scores'] = jaccard_scores\n",
    "        run_info['original-jaccard-score'] = round(np.mean(jaccard_scores), 3)\n",
    "    \n",
    "    return run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(xs, ys, color='r'):\n",
    "    new_xs = []\n",
    "    new_ys = []\n",
    "\n",
    "    for x, y in zip(xs, ys):\n",
    "        if y > -1:\n",
    "            new_xs.append(x)\n",
    "            new_ys.append(y)\n",
    "\n",
    "    # plt.plot(new_xs, new_ys, color)\n",
    "    plt.fill_between(new_xs, new_ys, interpolate=True, color=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base                                            , seed 13 |   -5.968; sum:   9.958; jacc mean:  0.821; jacc percent:     -0.450 || 9.958 & -5.968 & 0.821 & -0.45                                                                      \n",
      "Base + FT + BERT (fine-tuned, after convergence), seed 13 |   -8.382; sum:  10.184; jacc mean:  0.821; jacc percent:     -0.418 || 10.184 & -8.382 & 0.821 & -0.418                                                                    \n",
      "Base + FT + BERT (fine-tuned, after convergence), seed  7 |   -7.215; sum:  10.075; jacc mean:  0.820; jacc percent:     -0.574 || 10.075 & -7.215 & 0.82 & -0.574                                                                     \n",
      "Base + FT + BERT (fine-tuned, after convergence), seed 25 |   -5.639; sum:   9.927; jacc mean:  0.826; jacc percent:      0.108 || 9.927 & -5.639 & 0.826 & 0.108                                                                      \n",
      "-----------\n",
      "original jaccard similarity mean: 0.825\n",
      "original edit mean: 9.397\n"
     ]
    }
   ],
   "source": [
    "original_edit_distances = {}\n",
    "edit_distances_per_run = {}\n",
    "\n",
    "for run_name, run_unique_str in unique_runs.items():\n",
    "    for seed in [13, 7, 25]:\n",
    "        checkpoint_name = f'{run_unique_str}-seed{seed}'\n",
    "        run_info = get_run_info(language, checkpoint_name)\n",
    "        if run_info is None:\n",
    "            continue\n",
    "    \n",
    "        original_jaccard = run_info['original-jaccard-score']\n",
    "        original_jaccards = sum(run_info['original-jaccard-scores'])\n",
    "        jaccards = sum(run_info['jaccard-similarities'])\n",
    "        jaccard_improvement_percentage = -round(((1 - (float(jaccards) / original_jaccards)) * 100), 3)\n",
    "        \n",
    "        original_edit_mean = round(np.mean(run_info[\"original-edit-distances\"]), 3)\n",
    "        \n",
    "        original_edit_sum = sum(run_info[\"original-edit-distances\"])\n",
    "        predicted_edit_sum = sum(run_info[\"edit-distances\"])\n",
    "        improvement_percentage = run_info['improvement_percentage']\n",
    "        jaccard_similarity_mean = round(np.mean(run_info['jaccard-similarities']), 3)\n",
    "        edit_dist = round(np.mean(run_info[\"edit-distances\"]), 3)\n",
    "        print('{:48s}, seed {:2d} | {:8.3f}; sum: {:7.3f}; jacc mean: {:6.3f}; jacc percent: {:10.3f} || {:100s}'.format(run_name, seed, improvement_percentage, edit_dist, jaccard_similarity_mean, jaccard_improvement_percentage,\n",
    "                                                                                                                      f'{edit_dist} & {improvement_percentage} & {jaccard_similarity_mean} & {jaccard_improvement_percentage}'))\n",
    "        \n",
    "        original_edit_distances = run_info[\"original-edit-distances\"]\n",
    "        edit_distances_per_run['No correction'] = [x for x in original_edit_distances]\n",
    "        edit_distances_per_run[run_name] = [run_info[\"edit-distances\"][i] for i in range(len(original_edit_distances))]\n",
    "    \n",
    "print('-----------')\n",
    "print(f\"original jaccard similarity mean: {original_jaccard}\")\n",
    "print(f\"original edit mean: {original_edit_mean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(*dict_args):\n",
    "    \"\"\"\n",
    "    Given any number of dictionaries, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dictionaries.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c78d428cc8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_service.plot_overlapping_bars(\n",
    "    numbers_per_type=list(edit_distances_per_run.values()),\n",
    "    bar_titles=['\\\\textbf{' + x + '}' for x in list(edit_distances_per_run.keys())],\n",
    "    colors=['seagreen', 'peru', 'darkkhaki', 'black', 'gold'],\n",
    "    show_legend=True,\n",
    "    save_path=os.path.join(file_service.get_experiments_path(), 'post-ocr'),\n",
    "    filename=f'histogram-{language}',\n",
    "    tight_layout=True,\n",
    "    ylim=30,\n",
    "    xlim=42,\n",
    "    ylabel='\\\\textbf{\\% of total}',\n",
    "    xlabel='\\\\textbf{edit distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)",
   "language": "python",
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
