{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "from collections import Counter, OrderedDict\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Tuple, Callable\n",
    "import itertools\n",
    "from termcolor import colored\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from enums.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "\"--device cuda\",\n",
    "\"--data-folder\", \"..\\\\data\",\n",
    "\"--seed\", \"13\",\n",
    "\"--configuration\", \"rnn-simple\",\n",
    "\"--challenge\", \"named-entity-recognition\",\n",
    "\"--entity-tag-types\", \"literal-coarse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure container:\n",
    "from dependency_injection.ioc_container import IocContainer\n",
    "\n",
    "container = IocContainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_service = container.plot_service()\n",
    "file_service = container.file_service()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "languages = [\n",
    "    Language.English,\n",
    "    Language.French,\n",
    "    Language.German\n",
    "]\n",
    "\n",
    "counters_per_language = {\n",
    "    language: Counter() for language in languages\n",
    "}\n",
    "\n",
    "tag_mappings = {\n",
    "    'NE-COARSE-LIT': 'literal coarse',\n",
    "    'NE-COARSE-METO': 'metonymic coarse', \n",
    "    'NE-FINE-LIT': 'literal fine',\n",
    "    'NE-FINE-METO': 'metonymic fine',\n",
    "    'NE-FINE-COMP': 'component',\n",
    "    'NE-NESTED': 'nested'\n",
    "}\n",
    "\n",
    "other_entities_per_language_and_tag = {\n",
    "    lang: {\n",
    "        tag: [] for _, tag in tag_mappings.items()\n",
    "    } for lang in languages\n",
    "}\n",
    "\n",
    "version = '1.2'\n",
    "\n",
    "for language in languages:\n",
    "    language_path = file_service.get_data_path(language=language.value)\n",
    "    filenames = [x for x in os.listdir(language_path) if f'v{version}' in x and 'Copy' not in x and 'old' not in x]\n",
    "#     if language == Language.English:\n",
    "#         filenames = [x for x in filenames if 'train' not in x]\n",
    "\n",
    "    current_tokens_count = 0\n",
    "    current_decade = None\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join(language_path, filename), 'r', encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file, dialect=csv.excel_tab, quoting=csv.QUOTE_NONE)\n",
    "            for row in csv_reader:\n",
    "                if row['TOKEN'].startswith('# date') and (language != Language.English or 'train' not in filename):\n",
    "                    if current_decade is not None:\n",
    "                        counters_per_language[language][current_decade] += current_tokens_count\n",
    "\n",
    "                    current_decade = math.floor(float(row['TOKEN'][9:13]) / 10) * 10\n",
    "                    current_tokens_count = 0\n",
    "                elif not row['TOKEN'].startswith('#') and not row['TOKEN'].startswith(' '):\n",
    "                    if language != Language.English or 'train' not in filename:\n",
    "                        current_tokens_count += 1\n",
    "                    \n",
    "                    if 'train' in filename:\n",
    "                        for tag, tag_map in tag_mappings.items():\n",
    "                            other_entities_per_language_and_tag[language][tag_map].append(int(row[tag] == 'O'))\n",
    "                        \n",
    "\n",
    "unique_decades = list(sorted(set([label for x in counters_per_language.values() for label in x.keys()])))\n",
    "tags_per_decade = { }\n",
    "\n",
    "for language in languages:\n",
    "    language_path = file_service.get_data_path(language=language.value)\n",
    "    filenames = [x for x in os.listdir(language_path) if f'v{version}' in x and 'Copy' not in x and 'old' not in x]\n",
    "    if language == Language.English:\n",
    "        filenames = [x for x in filenames if 'train' not in x]\n",
    "\n",
    "    current_tokens_count = 0\n",
    "    current_decade = None\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join(language_path, filename), 'r', encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file, dialect=csv.excel_tab, quoting=csv.QUOTE_NONE)\n",
    "            for row in csv_reader:\n",
    "                if row['TOKEN'].startswith('# date'):\n",
    "                    current_decade = math.floor(float(row['TOKEN'][9:13]) / 10) * 10\n",
    "                elif not row['TOKEN'].startswith('#') and not row['TOKEN'].startswith(' '):\n",
    "                    coarse_entity_str = row['NE-COARSE-LIT']\n",
    "                    if coarse_entity_str.startswith('B-'):\n",
    "                        coarse_entity = coarse_entity_str[2:]\n",
    "                        if coarse_entity not in tags_per_decade.keys():\n",
    "                            tags_per_decade[coarse_entity] = Counter()\n",
    "\n",
    "                        tags_per_decade[coarse_entity][current_decade] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2dd47996f88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_labels = [x.value.capitalize() for x in counters_per_language.keys()]\n",
    "\n",
    "plot_service.plot_counters_histogram(\n",
    "    counter_labels=language_labels,\n",
    "    counters=counters_per_language.values(),\n",
    "    counter_colors=['firebrick', 'royalblue', 'black'],\n",
    "    save_path=file_service.get_experiments_path(),\n",
    "    filename='ner_tokens_per_language_and_decade',\n",
    "#     title='Tokens per decade and language',\n",
    "    ylabel='amount of tokens',\n",
    "    xlabel='decade')\n",
    "\n",
    "decade_labels = [str(x).capitalize() for x in tags_per_decade.keys()]\n",
    "\n",
    "plot_service.plot_counters_histogram(\n",
    "    counter_labels=decade_labels,\n",
    "    counters=tags_per_decade.values(),\n",
    "    counter_colors=['darkred', 'olive', 'orange', 'forestgreen', 'lightseagreen', 'lightcoral'],\n",
    "    save_path=file_service.get_experiments_path(),\n",
    "    filename='ner_mentions_per_tag_and_decade',\n",
    "#     title='Mentions per tag and decade',\n",
    "    ylabel='amount of mentions',\n",
    "    xlabel='decade')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_entities_per_language_and_tag[Language.English] = {\n",
    "    key: value for key, value in other_entities_per_language_and_tag[Language.English].items() if key == 'literal coarse'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'literal coarse': 84.75}, {'literal coarse': 90.17, 'metonymic coarse': 99.67, 'literal fine': 90.17, 'metonymic fine': 99.67, 'component': 96.45, 'nested': 99.54}, {'literal coarse': 91.55, 'metonymic coarse': 99.53, 'literal fine': 91.55, 'metonymic fine': 99.53, 'component': 97.16, 'nested': 99.7}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2dd47984848>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_other_percentage(language, tag):    \n",
    "    result = sum(other_entities_per_language_and_tag[language][tag]) / len(other_entities_per_language_and_tag[language][tag])\n",
    "    result *= 100\n",
    "    result = round(result, 2)\n",
    "    return result\n",
    "\n",
    "other_entities_per_tag = [\n",
    "    {\n",
    "        tag: get_other_percentage(lang, tag) for tag in other_entities_per_language_and_tag[lang].keys()\n",
    "    } for lang in languages\n",
    "]\n",
    "\n",
    "print(other_entities_per_tag)\n",
    "\n",
    "plot_service.plot_counters_histogram(\n",
    "    counter_labels=language_labels,\n",
    "    counters=other_entities_per_tag,\n",
    "    counter_colors=['firebrick', 'royalblue', 'black'],\n",
    "    save_path=file_service.get_experiments_path(),\n",
    "    filename='ner_other_entities_per_tag_and_language',\n",
    "#     title='Other entities per tag and language',\n",
    "    ylabel='amount of \\'O\\' entities',\n",
    "    xlabel='tag type',\n",
    "    plot_values_above_bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english - 84.75\n",
      "french - 95.95\n",
      "german - 96.5\n"
     ]
    }
   ],
   "source": [
    "sums = { lang:\n",
    "    sum([sum(other_entities_per_language_and_tag[lang][tag]) for tag in other_entities_per_language_and_tag[lang].keys()])\n",
    "    for lang in languages\n",
    "       }\n",
    "\n",
    "lens = { lang: \n",
    "    sum([len(other_entities_per_language_and_tag[lang][tag]) for tag in other_entities_per_language_and_tag[lang].keys()])\n",
    "    for lang in languages\n",
    "       }\n",
    "\n",
    "for lang in languages:\n",
    "    print(f'{lang.value} - {round((sums[lang] / lens[lang]) * 100, 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)",
   "language": "python",
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
