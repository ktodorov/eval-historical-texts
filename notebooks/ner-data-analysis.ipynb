{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "from collections import Counter, OrderedDict\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Tuple, Callable\n",
    "import itertools\n",
    "from termcolor import colored\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from enums.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "\"--device cuda\",\n",
    "\"--data-folder\", \"..\\\\data\",\n",
    "\"--seed\", \"13\",\n",
    "\"--configuration\", \"rnn-simple\",\n",
    "\"--challenge\", \"named-entity-recognition\",\n",
    "\"--entity-tag-types\", \"literal-coarse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure container:\n",
    "from dependency_injection.ioc_container import IocContainer\n",
    "\n",
    "container = IocContainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_service = container.plot_service()\n",
    "file_service = container.file_service()\n",
    "cache_service = container.cache_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "languages = [\n",
    "    Language.English,\n",
    "    Language.French,\n",
    "    Language.German\n",
    "]\n",
    "\n",
    "tag_mappings = {\n",
    "    'NE-COARSE-LIT': 'lit. coarse',\n",
    "    'NE-COARSE-METO': 'meto. coarse', \n",
    "    'NE-FINE-LIT': 'lit. fine',\n",
    "    'NE-FINE-METO': 'meto. fine',\n",
    "    'NE-FINE-COMP': 'component',\n",
    "    'NE-NESTED': 'nested'\n",
    "}\n",
    "\n",
    "version = '1.2'\n",
    "\n",
    "def get_tokens_info(file_service, languages, tag_mappings, version):\n",
    "\n",
    "    counters_per_language = {\n",
    "        language: Counter() for language in languages\n",
    "    }\n",
    "\n",
    "    other_entities_per_language_and_tag = {\n",
    "        lang: {\n",
    "            tag: [] for _, tag in tag_mappings.items()\n",
    "        } for lang in languages\n",
    "    }\n",
    "    \n",
    "    for language in languages:\n",
    "        language_path = file_service.get_data_path(language=language.value)\n",
    "        filenames = [x for x in os.listdir(language_path) if f'v{version}' in x and 'Copy' not in x and 'old' not in x]\n",
    "    #     if language == Language.English:\n",
    "    #         filenames = [x for x in filenames if 'train' not in x]\n",
    "\n",
    "        current_tokens_count = 0\n",
    "        current_decade = None\n",
    "        for filename in filenames:\n",
    "            with open(os.path.join(language_path, filename), 'r', encoding='utf-8') as csv_file:\n",
    "                csv_reader = csv.DictReader(csv_file, dialect=csv.excel_tab, quoting=csv.QUOTE_NONE)\n",
    "                for row in csv_reader:\n",
    "                    if row['TOKEN'].startswith('# date') and (language != Language.English or 'train' not in filename):\n",
    "                        if current_decade is not None:\n",
    "                            counters_per_language[language][current_decade] += current_tokens_count\n",
    "\n",
    "                        current_decade = math.floor(float(row['TOKEN'][9:13]) / 10) * 10\n",
    "                        current_tokens_count = 0\n",
    "                    elif not row['TOKEN'].startswith('#') and not row['TOKEN'].startswith(' '):\n",
    "                        if language != Language.English or 'train' not in filename:\n",
    "                            current_tokens_count += 1\n",
    "\n",
    "                        if 'train' in filename:\n",
    "                            for tag, tag_map in tag_mappings.items():\n",
    "                                other_entities_per_language_and_tag[language][tag_map].append(int(row[tag] == 'O'))\n",
    "                                \n",
    "    \n",
    "    return other_entities_per_language_and_tag, counters_per_language\n",
    "\n",
    "def get_tags_per_decade(file_service, languages, version):\n",
    "    tags_per_decade = { }\n",
    "    for language in languages:\n",
    "        language_path = file_service.get_data_path(language=language.value)\n",
    "        filenames = [x for x in os.listdir(language_path) if f'v{version}' in x and 'Copy' not in x and 'old' not in x]\n",
    "        if language == Language.English:\n",
    "            filenames = [x for x in filenames if 'train' not in x]\n",
    "\n",
    "        current_tokens_count = 0\n",
    "        current_decade = None\n",
    "        for filename in filenames:\n",
    "            with open(os.path.join(language_path, filename), 'r', encoding='utf-8') as csv_file:\n",
    "                csv_reader = csv.DictReader(csv_file, dialect=csv.excel_tab, quoting=csv.QUOTE_NONE)\n",
    "                for row in csv_reader:\n",
    "                    if row['TOKEN'].startswith('# date'):\n",
    "                        current_decade = math.floor(float(row['TOKEN'][9:13]) / 10) * 10\n",
    "                    elif not row['TOKEN'].startswith('#') and not row['TOKEN'].startswith(' '):\n",
    "                        coarse_entity_str = row['NE-COARSE-LIT']\n",
    "                        if coarse_entity_str.startswith('B-'):\n",
    "                            coarse_entity = coarse_entity_str[2:]\n",
    "                            if coarse_entity not in tags_per_decade.keys():\n",
    "                                tags_per_decade[coarse_entity] = Counter()\n",
    "\n",
    "                            tags_per_decade[coarse_entity][current_decade] += 1\n",
    "    \n",
    "    return tags_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_entities_per_language_and_tag, counters_per_language = cache_service.get_item_from_cache(\n",
    "    item_key='ner-data-analysis-tokens-info',\n",
    "    callback_function=lambda: (\n",
    "        get_tokens_info(file_service, languages, tag_mappings, version)))\n",
    "\n",
    "unique_decades = list(sorted(set([label for x in counters_per_language.values() for label in x.keys()])))\n",
    "    \n",
    "tags_per_decade = cache_service.get_item_from_cache(\n",
    "    item_key='ner-data-analysis-tags-info',\n",
    "    callback_function=lambda: (\n",
    "        get_tags_per_decade(file_service, languages, version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a34ab37488>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_labels = [x.value.capitalize() for x in counters_per_language.keys()]\n",
    "\n",
    "plot_service.plot_counters_histogram(\n",
    "    counter_labels=['\\\\textbf{' + x + '}' for x in language_labels],\n",
    "    counters=counters_per_language.values(),\n",
    "    counter_colors=['firebrick', 'royalblue', 'black'],\n",
    "    save_path=file_service.get_experiments_path(),\n",
    "    filename='ner_tokens_per_language_and_decade',\n",
    "#     title='Tokens per decade and language',\n",
    "    ylabel='\\\\textbf{amount of tokens}',\n",
    "    xlabel='\\\\textbf{decade}',\n",
    "    x_labels_rotation_angle=45)\n",
    "\n",
    "decade_labels = [str(x).capitalize() for x in tags_per_decade.keys()]\n",
    "\n",
    "plot_service.plot_counters_histogram(\n",
    "    counter_labels=['\\\\textbf{' + x + '}' for x in decade_labels],\n",
    "    counters=tags_per_decade.values(),\n",
    "    counter_colors=['darkred', 'olive', 'orange', 'forestgreen', 'lightseagreen', 'lightcoral'],\n",
    "    save_path=file_service.get_experiments_path(),\n",
    "    filename='ner_mentions_per_tag_and_decade',\n",
    "#     title='Mentions per tag and decade',\n",
    "    ylabel='\\\\textbf{amount of mentions}',\n",
    "    xlabel='\\\\textbf{decade}',\n",
    "    x_labels_rotation_angle=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_entities_per_language_and_tag[Language.English] = {\n",
    "    key: value for key, value in other_entities_per_language_and_tag[Language.English].items() if key == 'lit. coarse'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lit. coarse': 84.75}, {'lit. coarse': 90.17, 'meto. coarse': 99.67, 'lit. fine': 90.17, 'meto. fine': 99.67, 'component': 96.45, 'nested': 99.54}, {'lit. coarse': 91.55, 'meto. coarse': 99.53, 'lit. fine': 91.55, 'meto. fine': 99.53, 'component': 97.16, 'nested': 99.7}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\services\\plot_service.py:35: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax = plt.subplot()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a34b109c08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_other_percentage(language, tag):    \n",
    "    result = sum(other_entities_per_language_and_tag[language][tag]) / len(other_entities_per_language_and_tag[language][tag])\n",
    "    result *= 100\n",
    "    result = round(result, 2)\n",
    "    return result\n",
    "\n",
    "other_entities_per_tag = [\n",
    "    {\n",
    "        tag: get_other_percentage(lang, tag) for tag in other_entities_per_language_and_tag[lang].keys()\n",
    "    } for lang in languages\n",
    "]\n",
    "\n",
    "print(other_entities_per_tag)\n",
    "\n",
    "plt.ylim(top=120)\n",
    "plot_service.plot_counters_histogram(\n",
    "    counter_labels=['\\\\textbf{' + x + '}' for x in language_labels],\n",
    "    counters=[{'\\\\textbf{' + c + '}': v for c,v in x.items()} for x in other_entities_per_tag],\n",
    "    counter_colors=['firebrick', 'royalblue', 'black'],\n",
    "    save_path=file_service.get_experiments_path(),\n",
    "    filename='ner_other_entities_per_tag_and_language',\n",
    "#     title='Other entities per tag and language',\n",
    "    ylabel='\\\\textbf{amount of \\\\texttt{O} entities}',\n",
    "#     xlabel='tag type',\n",
    "    plot_values_above_bars=True,\n",
    "    values_above_bars_rotation=90,\n",
    "#     x_labels_rotation_angle=45,\n",
    "    space_x_labels_vertically=True,\n",
    "    external_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english - 84.75\n",
      "french - 95.95\n",
      "german - 96.5\n"
     ]
    }
   ],
   "source": [
    "sums = { lang:\n",
    "    sum([sum(other_entities_per_language_and_tag[lang][tag]) for tag in other_entities_per_language_and_tag[lang].keys()])\n",
    "    for lang in languages\n",
    "       }\n",
    "\n",
    "lens = { lang: \n",
    "    sum([len(other_entities_per_language_and_tag[lang][tag]) for tag in other_entities_per_language_and_tag[lang].keys()])\n",
    "    for lang in languages\n",
    "       }\n",
    "\n",
    "for lang in languages:\n",
    "    print(f'{lang.value} - {round((sums[lang] / lens[lang]) * 100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)",
   "language": "python",
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
