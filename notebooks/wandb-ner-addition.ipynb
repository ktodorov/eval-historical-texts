{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'french'\n",
    "\n",
    "sys.argv = [\n",
    "\"--device cuda\",\n",
    "\"--data-folder\", \"..\\\\data\",\n",
    "\"--seed\", \"13\",\n",
    "\"--configuration\", \"char-to-char-encoder-decoder\",\n",
    "\"--language\", language,\n",
    "\"--challenge\", \"post-ocr-correction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure container:\n",
    "from dependency_injection.ioc_container import IocContainer\n",
    "\n",
    "container = IocContainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'eval-historical-texts'\n",
    "project = 'post-ocr-correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wandb_runs():\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(path=f'{entity}/{project}', filters={\n",
    "        'createdAt': {\n",
    "            '$gt': '20200622000000'\n",
    "        },\n",
    "        'state': 'finished'\n",
    "#         'state': {\n",
    "#             '$ne': 'running'\n",
    "#         }\n",
    "    })\n",
    "\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 85 runs\n"
     ]
    }
   ],
   "source": [
    "runs = get_wandb_runs()\n",
    "print(f'Loaded {len(runs)} runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating... (16/85)\n",
      "Updating configuration...\n"
     ]
    }
   ],
   "source": [
    "def get_summary_value(run, key: str):\n",
    "    if key not in run.summary.keys():\n",
    "        return None\n",
    "\n",
    "    return run.summary[key]\n",
    "\n",
    "pretrained_model_type_key = 'pretrained_model_type'\n",
    "fine_tune_key = 'fine_tune'\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    if 'pretrained_model_type' in run.config.keys():\n",
    "        continue\n",
    " \n",
    "    clear_output(wait=True)\n",
    "    print(f'Updating... ({i}/{len(runs)})')\n",
    "    if len(run.config.keys()) == 0:# or fine_tune_key in run.config.keys() or pretrained_model_type_key in run.config.keys():\n",
    "        continue\n",
    "\n",
    "    if 'pretrained_model_type' in run.config.keys():\n",
    "        continue\n",
    "\n",
    "    # if 'pretrained_model_type' not in run.config.keys():\n",
    "    include_pretrained_model = run.config['include_pretrained_model']\n",
    "    include_fasttext_model = run.config['include_fasttext_model']\n",
    "    fine_tune_pretrained = run.config['fine_tune_pretrained']\n",
    "    fine_tune_after_convergence = run.config['fine_tune_after_convergence']\n",
    "\n",
    "    pretr_type = 'none'\n",
    "    if include_pretrained_model and include_fasttext_model:\n",
    "        pretr_type = 'both'\n",
    "    elif include_pretrained_model:\n",
    "        pretr_type = 'bert'\n",
    "    elif include_fasttext_model:\n",
    "        pretr_type = 'fast-text'\n",
    "\n",
    "    fine_tune = (fine_tune_pretrained or fine_tune_after_convergence)\n",
    "    fine_tune_type = 'none'\n",
    "    if fine_tune_pretrained:\n",
    "        fine_tune_type = 'from-start'\n",
    "    elif fine_tune_after_convergence:\n",
    "        fine_tune_type = 'after-convergence'\n",
    "    \n",
    "    print('Updating configuration...')\n",
    "    run.config.update({\n",
    "        'pretrained_model_type': pretr_type,\n",
    "        'fine_tune': fine_tune,\n",
    "        'fine_tune_type': fine_tune_type\n",
    "    })\n",
    "\n",
    "\n",
    "    # all_scores = [\n",
    "    #     get_summary_value(run, 'Best - f1-score-micro-partial-all-component'),\n",
    "    #     get_summary_value(run, 'Best - f1-score-micro-partial-all-literal-coarse'),\n",
    "    #     get_summary_value(run, 'Best - f1-score-micro-partial-all-literal-fine'),\n",
    "    #     get_summary_value(run, 'Best - f1-score-micro-partial-all-metonymic-coarse'),\n",
    "    #     get_summary_value(run, 'Best - f1-score-micro-partial-all-metonymic-fine'),\n",
    "    #     get_summary_value(run, 'Best - f1-score-micro-partial-all-nested')\n",
    "    # ]\n",
    "\n",
    "    # all_scores = [x for x in all_scores if x is not None]\n",
    "    # avg_score = np.mean(all_scores)\n",
    "        \n",
    "    # print('Updating summary...')\n",
    "    # run.summary.update({\n",
    "    #     'average_score': avg_score\n",
    "    # })\n",
    "\n",
    "    run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 85 runs\n"
     ]
    }
   ],
   "source": [
    "updated_runs = get_wandb_runs()\n",
    "print(f'Loaded {len(updated_runs)} runs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_speed_per_lang_and_pretr_type = {}\n",
    "\n",
    "for run in updated_runs:\n",
    "        \n",
    "    pretr_type = run.config[pretrained_model_type_key]\n",
    "    fine_tune_type = run.config['fine_tune_type']\n",
    "    model_key = f'{pretr_type} [{fine_tune_type}]'\n",
    "    \n",
    "    if model_key not in convergence_speed_per_lang_and_pretr_type.keys():\n",
    "        convergence_speed_per_lang_and_pretr_type[model_key] = {}\n",
    "        \n",
    "        \n",
    "    language = run.config['language']\n",
    "    if language not in convergence_speed_per_lang_and_pretr_type[model_key].keys():\n",
    "        convergence_speed_per_lang_and_pretr_type[model_key][language] = []\n",
    "        \n",
    "    runtime_minutes = float(run.summary['_runtime']) / 60\n",
    "    \n",
    "    convergence_speed_per_lang_and_pretr_type[model_key][language].append(runtime_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert [after-convergence] | 990.149 & 1277.19 & 2639.135 & \n",
      "both [after-convergence] | 1087.442 & 1473.291 & 2393.629 & \n",
      "bert [from-start] | 1218.266 & 1292.461 & 3153.515 & \n",
      "both [none] | 659.277 & 1037.03 & 1873.405 & \n",
      "bert [none] | 710.549 & 1070.933 & 1593.157 & \n",
      "both [from-start] | 1300.52 & 1529.498 & 3064.282 & \n",
      "none [none] | 475.882 & 662.735 & 1560.595 & \n",
      "fast-text [none] | 475.494 & 735.93 & 1481.484 & \n"
     ]
    }
   ],
   "source": [
    "languages = ['english', 'french', 'german']\n",
    "for pretr_type, convergence_speed_per_lang in convergence_speed_per_lang_and_pretr_type.items():\n",
    "    print(f'{pretr_type} | ', end='')\n",
    "    \n",
    "    for lang in languages:\n",
    "        times = convergence_speed_per_lang[lang]\n",
    "#         print(lang)\n",
    "        print(f'{round(np.mean(times), 3)} & ', end='')\n",
    "#         print('')\n",
    "#         print(times)\n",
    "        \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)",
   "language": "python",
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
