{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from collections import Counter, OrderedDict\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Tuple, Callable\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from enums.entity_tag_type import EntityTagType\n",
    "from enums.tag_measure_type import TagMeasureType\n",
    "from enums.tag_metric import TagMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'french'\n",
    "\n",
    "sys.argv = [\n",
    "\"--epochs 100000\",\n",
    "\"--device\", \"cuda\",\n",
    "\"--eval-freq\", \"30\",\n",
    "\"--seed\", \"13\",\n",
    "\"--configuration\", \"rnn-simple\",\n",
    "\"--learning-rate\", \"1e-2\",\n",
    "\"--metric-types\", \"f1-score\", \"precision\", \"recall\",\n",
    "\"--language\", \"french\",\n",
    "\"--challenge\", \"named-entity-recognition\",\n",
    "\"--batch-size\", \"32\",\n",
    "\"--checkpoint-name\", \"test\",\n",
    "\"--resume-training\",\n",
    "\"--data-folder\", '..\\\\data',\n",
    "\n",
    "\"--no-attention\",\n",
    "\n",
    "\"--pretrained-weights\", \"bert-base-multilingual-cased\",\n",
    "\"--fine-tune-learning-rate\", \"1e-4\",\n",
    "\"--pretrained-model-size\", \"768\",\n",
    "\"--pretrained-max-length\", \"512\",\n",
    "\"--include-fasttext-model\",\n",
    "\"--fasttext-model\", \"fr-model-skipgram-300minc20-ws5-maxn-6.bin\",\n",
    "\"--fasttext-model-size\", \"300\",\n",
    "\n",
    "\"--hidden-dimension\", \"512\",\n",
    "\"--bidirectional-rnn\",\n",
    "\"--number-of-layers\", \"1\",\n",
    "\"--embeddings-size\", \"128\",\n",
    "\n",
    "\"--learn-character-embeddings\",\n",
    "\"--character-embeddings-size\", \"32\",\n",
    "\"--character-hidden-size\", \"64\",\n",
    "\n",
    "\"--replace-all-numbers\",\n",
    "\n",
    "\"--merge-subwords\",\n",
    "\"--split-type\", \"multi-segment\",\n",
    "\n",
    "\"--entity-tag-types\", \"literal-fine\", \"literal-coarse\", \"metonymic-fine\", \"metonymic-coarse\", \"component\", \"nested\",\n",
    "\n",
    "\"--reset-training-on-early-stop\",\n",
    "\"--training-reset-epoch-limit\", \"5\",\n",
    "\"--patience\", \"20000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure container:\n",
    "from dependency_injection.ioc_container import IocContainer\n",
    "\n",
    "container = IocContainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average multi segments per document: 6.076433121019108\nAverage segments per multi segment:19.838258611315\nAverage multi segments per document: 5.190476190476191\nAverage segments per multi segment:19.33067474853189\nLoaded char-vocab-fr-1.2\n"
    }
   ],
   "source": [
    "tag_metrics_service = container.tag_metrics_service()\n",
    "process_service = container.process_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_tag_types = [\n",
    "    EntityTagType.Component,\n",
    "    EntityTagType.LiteralCoarse,\n",
    "    EntityTagType.LiteralFine,\n",
    "    EntityTagType.MetonymicCoarse,\n",
    "    EntityTagType.MetonymicFine,\n",
    "    EntityTagType.Nested\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_outputs_per_tag = None\n",
    "with open('temp.pickle', 'rb') as temp_file:\n",
    "    eval_outputs_per_tag = pickle.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp-orig.pickle', 'rb') as temp_file:\n",
    "    orig_targ, scores = pickle.load(temp_file)\n",
    "\n",
    "orig_targ = [x.lower() for x in orig_targ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_entities_per_tag = {\n",
    "    entity_tag_type: process_service.get_main_entities(\n",
    "        entity_tag_type)\n",
    "    for entity_tag_type in entity_tag_types\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_segment_eval_metrics(eval_outputs_per_tag):\n",
    "    predictions_per_doc = {}\n",
    "    documents_predictions = {}\n",
    "    documents_targets = {}\n",
    "    for entity_tag_type, validation_predictions in eval_outputs_per_tag.items():\n",
    "        documents_predictions[entity_tag_type] = []\n",
    "        documents_targets[entity_tag_type] = []\n",
    "\n",
    "        for prediction in validation_predictions:\n",
    "            document_id = prediction[2]\n",
    "            segment_idx = prediction[3]\n",
    "\n",
    "            if document_id not in predictions_per_doc.keys():\n",
    "                predictions_per_doc[document_id] = {}\n",
    "\n",
    "            predictions_per_doc[document_id][segment_idx] = (\n",
    "                prediction[0], prediction[1])\n",
    "\n",
    "        \n",
    "        for predictions_per_segment in predictions_per_doc.values():\n",
    "            document_predictions = []\n",
    "            document_targets = []\n",
    "\n",
    "            segment_ids = list(sorted(predictions_per_segment.keys()))\n",
    "            for segment_idx in segment_ids:\n",
    "                document_predictions.extend(\n",
    "                    predictions_per_segment[segment_idx][0])\n",
    "                document_targets.extend(\n",
    "                    predictions_per_segment[segment_idx][1])\n",
    "\n",
    "            documents_predictions[entity_tag_type].append(document_predictions)\n",
    "            documents_targets[entity_tag_type].append(document_targets)\n",
    "\n",
    "            \n",
    "    return documents_predictions, documents_targets\n",
    "\n",
    "def calculate_tags(documents_predictions, documents_targets, main_entities_per_tag):\n",
    "    entity_tag_types = documents_predictions.keys()\n",
    "    for entity_tag_type in entity_tag_types:\n",
    "        for (document_predictions, document_targets)  in zip(documents_predictions[entity_tag_type], documents_targets[entity_tag_type]):\n",
    "\n",
    "            should_print = False\n",
    "            if entity_tag_type == EntityTagType.LiteralCoarse:\n",
    "                joined_target = ','.join(document_targets).lower()\n",
    "                print(f'orig score: {scores[orig_targ.index(joined_target)]}')\n",
    "                should_print = True\n",
    "\n",
    "            tag_metrics_service.add_predictions(\n",
    "                [document_predictions],\n",
    "                [document_targets],\n",
    "                main_entities_per_tag[entity_tag_type],\n",
    "                entity_tag_type,\n",
    "                should_print=should_print)\n",
    "            \n",
    "            if entity_tag_type == EntityTagType.LiteralCoarse:\n",
    "                print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_coarse_outputs = {EntityTagType.LiteralCoarse: eval_outputs_per_tag[EntityTagType.LiteralCoarse] }\n",
    "lit_coarse_entities = {EntityTagType.LiteralCoarse: main_entities_per_tag[EntityTagType.LiteralCoarse] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_predictions, documents_targets = compute_multi_segment_eval_metrics(lit_coarse_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_targets = [','.join(x).lower() for x in documents_targets[EntityTagType.LiteralCoarse]]\n",
    "\n",
    "idx_match = {}\n",
    "for i, targ in enumerate(orig_targ):\n",
    "    for k, joined_target in enumerate(joined_targets):\n",
    "        if targ == joined_target:\n",
    "            idx_match[i] = k\n",
    "            break\n",
    "\n",
    "documents_predictions = {k: [v[i] for i in idx_match.values()] for k, v in documents_predictions.items()}\n",
    "documents_targets = {k: [v[i] for i in idx_match.values()] for k, v in documents_targets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for original, ours in zip(orig_targ, documents_targets[EntityTagType.LiteralCoarse]):\n",
    "    assert original == ','.join(ours).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[10, 38, 249]\n"
    }
   ],
   "source": [
    "# print(','.join(documents_predictions[EntityTagType.LiteralCoarse][0]).lower())\n",
    "# print('-------------------------------')\n",
    "# print('O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O,O,O,O,B-PERS,I-PERS,I-PERS,O,O,B-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-PERS,I-PERS,I-PERS,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'.lower())\n",
    "# print('-------------------------------')\n",
    "# print(orig_targ[0])\n",
    "\n",
    "indices = [i for i, x in enumerate(documents_predictions[EntityTagType.LiteralCoarse][0]) if x == \"B-loc\"]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "orig score: {'correct': 3, 'incorrect': 0, 'partial': 1, 'missed': 2, 'spurious': 1, 'possible': 6, 'actual': 5, 'TP': 3, 'FP': 2, 'FN': 3, 'P_micro': 0, 'R_micro': 0, 'F1_micro': 0, 'P_macro_doc': [], 'R_macro_doc': [], 'F1_macro_doc': []}\n[[Entity(e_type='loc', start_offset=10, end_offset=10)], [Entity(e_type='pers', start_offset=21, end_offset=32)], [Entity(e_type='loc', start_offset=38, end_offset=38)], [Entity(e_type='loc', start_offset=121, end_offset=121)], [Entity(e_type='org', start_offset=167, end_offset=169)], [Entity(e_type='pers', start_offset=398, end_offset=400)]]\n[[Entity(e_type='loc', start_offset=10, end_offset=10)], [Entity(e_type='pers', start_offset=21, end_offset=23)], [Entity(e_type='pers', start_offset=26, end_offset=32)], [Entity(e_type='loc', start_offset=38, end_offset=38)], [Entity(e_type='loc', start_offset=249, end_offset=253)], [Entity(e_type='pers', start_offset=398, end_offset=400)]]\n"
    },
    {
     "output_type": "error",
     "ename": "Exception",
     "evalue": "test",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d2ea9cefe760>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalculate_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlit_coarse_entities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-6109b8ac5166>\u001b[0m in \u001b[0;36mcalculate_tags\u001b[1;34m(documents_predictions, documents_targets, main_entities_per_tag)\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mmain_entities_per_tag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentity_tag_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mentity_tag_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 should_print=should_print)\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentity_tag_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEntityTagType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLiteralCoarse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive\\Learning\\University\\Masters-UvA\\Thesis\\code\\eval-historical-texts\\services\\tag_metrics_service.py\u001b[0m in \u001b[0;36madd_predictions\u001b[1;34m(self, prediction_tags, target_tags, main_entities, entity_tag_type, should_print)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mmain_entities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mcalculate_doc_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             should_print=should_print)\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_overall_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive\\Learning\\University\\Masters-UvA\\Thesis\\code\\eval-historical-texts\\services\\tag_metrics_service.py\u001b[0m in \u001b[0;36m_aggregate_batch\u001b[1;34m(self, results, results_per_type, prediction_tags, target_tags, main_entities, calculate_doc_scores, should_print)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_named_entities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_named_entities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_named_entities\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_named_entities\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: test"
     ]
    }
   ],
   "source": [
    "calculate_tags(documents_predictions, documents_targets, lit_coarse_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_stats = tag_metrics_service.calculate_overall_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{<TagMetric.Correct: 'correct'>: 0,\n <TagMetric.Incorrect: 'incorrect'>: 0,\n <TagMetric.Partial: 'partial'>: 0,\n <TagMetric.Missed: 'missed'>: 0,\n <TagMetric.Spurious: 'spurious'>: 0,\n <TagMetric.Possible: 'possible'>: 0,\n <TagMetric.Actual: 'actual'>: 0,\n <TagMetric.TruePositives: 'TP'>: 0,\n <TagMetric.FalsePositives: 'FP'>: 0,\n <TagMetric.PrecisionMicro: 'precision-micro'>: 0,\n <TagMetric.RecallMicro: 'recall-micro'>: 0,\n <TagMetric.F1ScoreMicro: 'f1-score-micro'>: 0,\n <TagMetric.PrecisionMacroDoc: 'precision-macro-doc'>: 0,\n <TagMetric.RecallMacroDoc: 'recall-macro-doc'>: 0,\n <TagMetric.F1ScoreMacroDoc: 'f1-score-macro-doc'>: 0,\n <TagMetric.PrecisionMacro: 'precision-macro'>: 0,\n <TagMetric.RecallMacro: 'recall-macro'>: 0,\n <TagMetric.F1ScoreMacro: 'f1-score-macro'>: 0,\n <TagMetric.PrecisionMacroDocStd: 'precision-macro-doc-std'>: 0,\n <TagMetric.RecallMacroDocStd: 'recall-macro-doc-std'>: 0,\n <TagMetric.F1ScoreMacroDocStd: 'f1-score-macro-doc-std'>: 0}"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "overall_stats[EntityTagType.LiteralCoarse][0][TagMeasureType.Partial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# literal_coarse_predictions = documents_predictions[EntityTagType.LiteralCoarse]\n",
    "# print([len(x) for x in literal_coarse_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original_targets = 'O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O,O,O,O,B-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS'.lower()\n",
    "# full_og_targets = 'O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O,O,O,O,B-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,I-PERS,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-ORG,I-ORG,I-ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-PERS,I-PERS,I-PERS,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'.lower()\n",
    "\n",
    "# joined_targets = [','.join(x).lower() for x in documents_targets[EntityTagType.LiteralCoarse]]\n",
    "\n",
    "# idx_match = {}\n",
    "# for i, joined_target in enumerate(joined_targets):\n",
    "#     for k, targ in enumerate(orig_targ):\n",
    "#         if targ == joined_target:\n",
    "#             idx_match[i] = k\n",
    "#             break\n",
    "\n",
    "# idx_match\n",
    "# a = [i for i in range(len(first_30)) if full_og_targets == first_30[i]]\n",
    "# print(a)\n",
    "# first_30 = [x for x in first_30 if full_og_targets in x]\n",
    "# for x in first_30:\n",
    "#     print(x)\n",
    "#     print(original_targets)\n",
    "#     print('--------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b",
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}