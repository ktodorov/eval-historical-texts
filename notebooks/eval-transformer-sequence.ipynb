{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "import sys\n",
    "# Add the ptdraft folder path to the sys.path list\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.transformer_model import TransformerModel\n",
    "\n",
    "from services.data_service import DataService\n",
    "from services.vocabulary_service import VocabularyService\n",
    "from services.metrics_service import MetricsService\n",
    "from services.log_service import LogService\n",
    "from services.tokenizer_service import TokenizerService\n",
    "from services.file_service import FileService\n",
    "from services.pretrained_representations_service import PretrainedRepresentationsService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentService:\n",
    "    def __init__(self):\n",
    "        self.values = {\n",
    "            'device': 'cuda',\n",
    "            'sentence_piece_vocabulary_size': 30522,\n",
    "            'hidden_dimension': 32,\n",
    "            'number_of_layers': 1,\n",
    "            'number_of_heads': 1,\n",
    "            'dropout': 0,\n",
    "            'data_folder': '../data',\n",
    "            'challenge': 'ocr',\n",
    "            'configuration': 'transformer-sequence',\n",
    "            'language': 'english',\n",
    "            'pretrained_weights': 'bert-base-cased',\n",
    "            'metric_types': ['jaccard-similarity', 'levenshtein-distance'],\n",
    "            'checkpoint_folder': None,\n",
    "            'output_folder': 'results'\n",
    "        }\n",
    "    \n",
    "    def get_argument(self, key: str) -> object:\n",
    "        return self.values[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary\n"
     ]
    }
   ],
   "source": [
    "arg_service = ArgumentService()\n",
    "\n",
    "device = arg_service.get_argument('device')\n",
    "\n",
    "data_service = DataService()\n",
    "file_service = FileService(\n",
    "    arg_service)\n",
    "\n",
    "vocabulary_service = VocabularyService(\n",
    "    data_service=data_service,\n",
    "    file_service=file_service)\n",
    "\n",
    "metrics_service = MetricsService()\n",
    "\n",
    "log_service = LogService(\n",
    "    arguments_service=arg_service,\n",
    "    external_logging_enabled=False)\n",
    "\n",
    "tokenizer_service = TokenizerService(\n",
    "    arguments_service=arg_service,\n",
    "    file_service=file_service)\n",
    "\n",
    "pretrained_representations_service = PretrainedRepresentationsService(\n",
    "    include_pretrained=True,\n",
    "    pretrained_model_size=768,\n",
    "    pretrained_weights='bert-base-cased',\n",
    "    pretrained_max_length=512,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(\n",
    "    arguments_service=arg_service,\n",
    "    data_service=data_service,\n",
    "    vocabulary_service=vocabulary_service,\n",
    "    metrics_service=metrics_service,\n",
    "    log_service=log_service,\n",
    "    tokenizer_service=tokenizer_service).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BEST_checkpoint\n"
     ]
    }
   ],
   "source": [
    "checkpoints_path = os.path.join('..', file_service.get_checkpoints_path())\n",
    "a = model.load(checkpoints_path, 'BEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = os.path.join('..', 'data', 'vocabularies', 'bert-base-cased-vocab.txt')\n",
    "tokenizer = BertWordPieceTokenizer(vocab_path, lowercase=False)\n",
    "\n",
    "ocr_text = \"bk. I, 70 AN ENGLISH ANTHOLOGY. And earthly power doth then show likest God's When mercy seasons justice. Therefore, Jew, Though justice be thy plea, consider this -That in the course of justice, none of us Should see salvation we do pray for mercy And that same prayer doth teach us all to render The deeds of mercy. 1596. - Merchant of Venice, iv. 1 LVII. THE POWER OF MUSIC. How sweet the moonlight sleeps upon this bank ! Here will we sit, and let the sounds of music Creep in our ears soft stillness and the night Become the touches of sweet harmony. Sit, Jessica. Look how the floor of heaven Is thick inlaid with patines of bright gold There's not the smallest orb which thou behold'st, But in his motion like an angel sings, Still quiring to the young-eyed cherubins Such harmony is in immortal souls But whilst this muddy vesture of decay Doth grossly close it in, we cannot hear it. Enter Musicians. Come, ho ! and wake Diana with a hymn With sweetest touches pierce your mistress' ear. And draw her home with music. yes. I'm never merry when I hear sweet music. Lor. The reason is, your spirits are attentive And, do but note a wild and wanton herd Or race ot youthful and unhandled colts, Fetching mad bounds, bellowing and neighing loud Which is the hot condition of their blood\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg = \" earthly power doth then show likest God's When mercy seasons justice. Therefore, Jew, Though justice be thy plea, consider this-That in the course of justice, none of us Should see salvation we do pray for mercy And that same prayer doth teach us all to render The deeds of mercy. 1596. -Merchant of Venice, iv. 1. LVII. THE POWER OF MUSIC. HOW sweet the moonlight sleeps upon this bank ! Here will we sit, and let the sounds of music Creep in our ears soft stillness and the night Become the touches of sweet harmony. Sit, Jessica. Look how the floor of heaven Is thick inlaid with patines of bright gold There's not the smallest orb which thou behold'st, But in his motion like an angel sings, Still quiring to the young-eyed cherubins Such harmony is in immortal souls But whilst this muddy vesture of decay Doth grossly close it in, we cannot hear it. Enter Musicians. Come, ho ! and wake Diana with a hymn With sweetest touches pierce your mistress' ear. And draw her home with music. Yes. I'm never merry when I hear sweet music. Lor. The reason is, your spirits are attentive And, do but note a wild and wanton herd Or race of youthful and unhandled colts, Fetching mad bounds, bellowing and neighing loud, Which is the hot condition of their blood\"\n",
    "trg_tokens = tokenizer.encode(ocr_text).ids\n",
    "# print(trg_tokens)\n",
    "\n",
    "ocr_v = vocabulary_service.string_to_ids(ocr_text)\n",
    "# print(ocr_v)\n",
    "\n",
    "trg_v = vocabulary_service.string_to_ids(trg)\n",
    "# print(trg_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]The ATE AThe The The AThe AThe AThe ATE ATE AThe TE The ATE AThe The te The TE The The The  ATE The The AThe  The AThe The The The  Me  AThe The TE TE ATE AThe Mre TE The AThe ATE  Mre  The AThe The The AThe ATE te AThe A ATE  The AThe ATE AThe The The ATE The  AThe Aan he he he he he he he he ore he he he he he f he te he oure f he he he he te he he he he he he te he he he or he he ore he he he te he he he f te te he he he he te he he he he he te he he he he he f he f he pre he he he te he he he he he he he he he he he he he f he he he te ore he oure he he te he he he he ore he or he te he he he he te f he he he he an he he he ore on he he he he ore f he he he he he he he he w he f he te he ore he he te he f he he he ore he f he he te he he he ore he on he he he he oure he he he he he f he he pre he he f he he he he he he he te f he he he he he he he he he f he he te an te te f he te te te te f he te w te te te te w w te te he he te wan te w he te te te he te te f he te w te he te w te te te te he te te te te te f f te he te te he he he f he te te he he he te he he he w te he te te te he te te te te an he w he te w te he te te te t te he te te he te te f te he te te te he te te te te he te te w f te f he he he te te te he he he te w te he te te an w he he w t te te he te te te te\n"
     ]
    }
   ],
   "source": [
    "max_len = len(ocr_text) + 10\n",
    "model.eval()\n",
    "\n",
    "tokens = tokenizer.encode(ocr_text).ids\n",
    "# print(tokens)\n",
    "\n",
    "src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "src_mask = model.make_src_mask(src_tensor)\n",
    "\n",
    "def _split_to_chunks(list_to_split: list, chunk_size: int, overlap_size: int):\n",
    "        result = [list_to_split[i:i+chunk_size]\n",
    "                  for i in range(0, len(list_to_split), chunk_size-overlap_size)]\n",
    "        return result\n",
    "    \n",
    "def _get_pretrained_representation(ocr_aligned):\n",
    "    ocr_aligned_splits = [ocr_aligned]\n",
    "    if len(ocr_aligned) > 512:\n",
    "        ocr_aligned_splits = _split_to_chunks(\n",
    "            ocr_aligned, chunk_size=512, overlap_size=2)\n",
    "\n",
    "    pretrained_outputs = torch.zeros(\n",
    "        (len(ocr_aligned_splits), 512, 768)).to(device)\n",
    "    \n",
    "    for i, ocr_aligned_split in enumerate(ocr_aligned_splits):\n",
    "        ocr_aligned_tensor = torch.Tensor(\n",
    "            ocr_aligned_split).unsqueeze(0).long().to(device)\n",
    "        pretrained_output = pretrained_representations_service.get_pretrained_representation(\n",
    "            ocr_aligned_tensor)\n",
    "\n",
    "        _, output_length, _ = pretrained_output.shape\n",
    "\n",
    "        pretrained_outputs[i, :output_length, :] = pretrained_output\n",
    "\n",
    "    pretrained_result = pretrained_outputs.view(\n",
    "        -1, 768)\n",
    "\n",
    "    return pretrained_result\n",
    "\n",
    "pretrained_representation = _get_pretrained_representation(tokens)[:len(tokens)].unsqueeze(0)\n",
    "# print(pretrained_representation.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    enc_src = model.encoder(src_tensor, src_mask, pretrained_representation)\n",
    "    \n",
    "# trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "trg_indexes = [vocabulary_service.cls_token]\n",
    "# trg_indexes = trg_v\n",
    "\n",
    "for i in range(max_len):\n",
    "\n",
    "    trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "    \n",
    "    pred_token = output.argmax(2)[:,-1].item()\n",
    "    \n",
    "    trg_indexes.append(pred_token)\n",
    "\n",
    "    if pred_token == vocabulary_service.eos_token:\n",
    "        print('EOS token predicted... Breaking...')\n",
    "        break\n",
    "\n",
    "# trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "trg_tokens = vocabulary_service.ids_to_string(trg_indexes)\n",
    "print(trg_tokens)\n",
    "\n",
    "# return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('eval-env': conda)",
   "language": "python",
   "name": "python37564bitevalenvcondab07c5918277c4c33a244293f5160293b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
